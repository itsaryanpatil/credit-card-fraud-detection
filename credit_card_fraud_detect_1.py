# -*- coding: utf-8 -*-
"""credit card fraud detect 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I8VewXILyqKSal2PgRsfqF77QhPvMG6d
"""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d mlg-ulb/creditcardfraud
!unzip creditcardfraud.zip
# this was to load the dataset into our consideration of files for this notebook

import pandas as pd
# this kinda helps in reading through or accessing info from csv type tabular files
# similar things were directly used in R
df = pd.read_csv('creditcard.csv')
# to read the csv file
df

df['Class'].value_counts()
# this tells within that column, Class here
# what are the different values and how many times they occur
# this helps us in knowing positive and negative classes, their frequency
# useful in classification like here

#df.hist(bins = 30, figsize = (30,30))
# trying this hist function more to understand it
df.hist(bins = 20, figsize = (20,20))
# bins = no. of intervals
#figsize = dimensions

df.describe()
# summary of the dataset

from sklearn.preprocessing import RobustScaler
# scikit learn
df_2 = df.copy()
#copy the database into df_2 so original data is not affected
df_2['Amount'] = RobustScaler().fit_transform(df_2['Amount'].to_numpy().reshape(-1,1))
# replace the original values in the 'Amount' column with their scaled values
# Converts the 'Amount' column to a NumPy array.
# Reshapes the NumPy array to a 2D array with one column and as many rows as necessary (the -1 allows the rows to be determined automatically)
# Fits the RobustScaler to the data and transforms it in one step
#df_2['Amount'].hist()
time = df_2['Time']
df_2['Time'] = (time - time.min())/(time.max() - time.min())
df_2

df_2 = df_2.sample(frac=1, random_state=1)
df_2
# randomly shuffled order
# frac=1: Specifies that you want to sample 100% of the rows
# random_state=1: Sets a seed for the random number generator, ensuring that the shuffling is reproducible. Using the same random_state value will always produce the same shuffled DataFrame when you run the code again

train, test, val = df_2[:240000], df_2[240000:262000], df_2[262000:]
# here we spilt the dataset effectively
train['Class'].value_counts(), test['Class'].value_counts(), val['Class'].value_counts()
# we find how many positive and negative classes are in each

train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()
train_np.shape, test_np.shape, val_np.shape
# conversion to numpy arrays for each split dataset

# x -> input, y -> output

x_train, y_train = train_np[:, :-1], train_np[:, -1]
# -1 refers to last column here input has everything except it,
# output has only that, this for every row
x_test, y_test = test_np[:, :-1], test_np[:, -1]
x_val, y_val = val_np[:, :-1], val_np[:, -1]
#same for test and val set
x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape

# train a logistic regression model on the training data and evaluate its performance

from sklearn.linear_model import LogisticRegression
logistic_model = LogisticRegression()
# instance of the LogisticRegression model with default parameters.
logistic_model.fit(x_train, y_train)
# trains the logistic regression model
logistic_model.score(x_train, y_train)
# returns the mean accuracy
# accuracy score is the ratio of correctly predicted
# instances to the total instances in the training set

# evaluate the performance of the
# logistic regression model on the validation data

from sklearn.metrics import classification_report
y_val_pred = logistic_model.predict(x_val)
# predictions on the validation set
print(classification_report(y_val, y_val_pred, target_names=['Not Fraud', 'Fraud']))
# if 0 Not Fraud and 1 Fraud, target names our convinience
# comparison is done

"""Precision: The ratio of true positive predictions to the total number of positive predictions (true positives + false positives). It indicates how many of the predicted positive instances are actually positive.

Recall: The ratio of true positive predictions to the total number of actual positive instances (true positives + false negatives). It indicates how many of the actual positive instances are correctly predicted.

F1-Score: The harmonic mean of precision and recall. It provides a single metric that balances the two.

Support: The number of actual occurrences of each class in the validation set.

understand what are false negatives and false positives

The macro average is the unweighted mean of the metrics, treating all classes equally, while the weighted average takes class support into account.
"""

# shallow neural network using the TensorFlow Keras API

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint
# Import Necessary Modules

shallow_nn = Sequential()
# Initialize the Sequential Model
shallow_nn.add(InputLayer((x_train.shape[1],)))
# add input layer, number of features in the training data, here 30
shallow_nn.add(Dense(2, 'relu'))
# This adds a dense (fully connected) layer with
# 2 units and ReLU activation function.
shallow_nn.add(BatchNormalization())
# This normalizes the activations of the previous layer at each batch,
# which helps with training stability and speed.
shallow_nn.add(Dense(1, 'sigmoid'))
# This adds the output layer with 1 unit and a sigmoid activation
# function, suitable for binary classification tasks.

checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)
# This callback saves the model with the
# best validation accuracy during training.
shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# This specifies the Adam optimizer,
# binary cross-entropy loss function, and
# accuracy as the metric to monitor.

shallow_nn.summary()

shallow_nn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)

"""The training process will run for 5 epochs, and the model checkpoint callback will save the best version of the model based on the validation accuracy.

fit method: This method trains the model on the training data for a specified number of epochs and validates it on the validation data.

epochs=5: The number of complete passes through the training dataset.

callbacks=[checkpoint]: A list of callback functions to apply during training, in this case, saving the best model based on validation accuracy.


"""

def neural_net_predictions(model, x):
  return (model.predict(x).flatten() > 0.5).astype(int);
neural_net_predictions(shallow_nn, x_val)

print(classification_report(y_val, neural_net_predictions(shallow_nn, x_val), target_names=['Not Fraud', 'Fraud']))

# Random Forest model on the training data

from sklearn.ensemble import RandomForestClassifier
# Import Necessary Modules
rf = RandomForestClassifier(max_depth=2, n_jobs=-1)
# Initialize and Train the Random Forest Classifier
rf.fit(x_train, y_train)
print(classification_report(y_val, rf.predict(x_val), target_names=['Not Fraud', 'Fraud']))
# max_depth=2: Limits the maximum depth of each tree in the forest, which can help prevent overfitting.
# n_jobs: This parameter specifies the number of CPU cores to use for the computatio

# train a Gradient Boosting model on the training data

from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=3)
gbc.fit(x_train, y_train)
# n_estimators=50: The number of boosting stages to be run. More estimators
# usually improve performance but increase training time.

# learning_rate=1.0: The learning rate shrinks the contribution of each tree.
# There is a trade-off between learning_rate and n_estimators.

# random_state=0: Ensures reproducibility by fixing the
# seed of the random number generator.
print(classification_report(y_val, gbc.predict(x_val), target_names=['Not Fraud', 'Fraud']))

# train a linear Support Vector Classifier on the training data
from sklearn.svm import LinearSVC
svc = LinearSVC(class_weight='balanced')
# class_weight='balanced': This parameter adjusts the weights
# inversely proportional to the class frequencies in the input data.
# This is useful for handling class imbalance,
# ensuring that the model pays more attention to the
# minority class (in this case, 'Fraud').

svc.fit(x_train, y_train)
print(classification_report(y_val, svc.predict(x_val), target_names=['Not Fraud', 'Fraud']))

frauds = df_2.query('Class == 1')
not_frauds = df_2.query('Class == 0')

"""the issue we have faced so far is that the dataset is highly imbalanced.
What it does is affect the performance of our model, its like even if the ml model just decides the answer is going to be not fraud, even then it will have 99.8% accuracy which might seem good but takes away the point of detecting the fraud.
When we see how many frauds have been detected its too less, there are so many not frauds that the algos cant differentitate easily between them.

Now we convert it into a balanced dataset. here we randomly pick equal no. of not frauds, and give the algos a 50-50 on frauds and not frauds so there are hgiher stakes for it to understand the difference between them.

Know that this is just to train the thing and might work worse for the whole thing
"""

balanced_df = pd.concat([frauds, not_frauds.sample(len(frauds), random_state=1)])
balanced_df['Class'].value_counts()

balanced_df = balanced_df.sample(frac=1, random_state=1)
balanced_df
# randomising it

balanced_df_np = balanced_df.to_numpy()
# just like earlier we do the ssame stuff on our smaller balanced dataset
x_train_b, y_train_b = balanced_df_np[:700, :-1], balanced_df_np[:700, -1].astype(int)
x_test_b, y_test_b = balanced_df_np[700:842, :-1], balanced_df_np[700:842, -1].astype(int)
x_val_b, y_val_b = balanced_df_np[842:, :-1], balanced_df_np[842:, -1].astype(int)
x_train_b.shape, y_train_b.shape, x_test_b.shape, y_test_b.shape, x_val_b.shape, y_val_b.shape

pd.Series(y_train_b).value_counts(), pd.Series(y_test_b).value_counts(), pd.Series(y_val_b).value_counts()

from sklearn.linear_model import LogisticRegression
logistic_model_b = LogisticRegression()
logistic_model_b.fit(x_train_b, y_train_b)
logistic_model_b.score(x_train_b, y_train_b)
# same logistic regression model on balanced
# you can notice lesser accuracy but that is because the stakes are high as well

print(classification_report(y_val_b, logistic_model_b.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))

"""now the precision and recall are much higher for fraud and the f1 score is great as well but at the same time it affected the not frauds as well compared to earlier. tradeoffs are common"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint

shallow_nn_b = Sequential()
shallow_nn_b.add(InputLayer((x_train_b.shape[1],)))
shallow_nn_b.add(Dense(2, 'relu'))
shallow_nn_b.add(BatchNormalization())
shallow_nn_b.add(Dense(1, 'sigmoid'))

checkpoint = ModelCheckpoint('shallow_nn_b', save_best_only=True)
shallow_nn_b.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

shallow_nn_b.summary()

shallow_nn_b.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=checkpoint)

def neural_net_predictions(model, x):
  return (model.predict(x).flatten() > 0.5)
neural_net_predictions(shallow_nn_b, x_val)

print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b, x_val_b), target_names=['Not Fraud', 'Fraud']))

"""here the result is much better but it feels like it will overfit, so we can make the model a bit less complicated"""

shallow_nn_b1 = Sequential()
shallow_nn_b1.add(InputLayer((x_train.shape[1],)))
shallow_nn_b1.add(Dense(1, 'relu'))
shallow_nn_b1.add(BatchNormalization())
shallow_nn_b1.add(Dense(1, 'sigmoid'))

checkpoint = ModelCheckpoint('shallow_nn_b1', save_best_only=True)
shallow_nn_b1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
shallow_nn_b1.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=checkpoint)

shallow_nn_b1.fit(x_train_b, y_train_b, validation_data=(x_val_b, y_val_b), epochs=40, callbacks=checkpoint)

print(classification_report(y_val_b, neural_net_predictions(shallow_nn_b1, x_val_b), target_names=['Not Fraud', 'Fraud']))

from sklearn.ensemble import RandomForestClassifier

rf_b = RandomForestClassifier(max_depth=2, n_jobs=-1)
rf_b.fit(x_train_b, y_train_b)
print(classification_report(y_val_b, rf_b.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))

from sklearn.ensemble import GradientBoostingClassifier

gbc_b = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=2, random_state=0)
gbc_b.fit(x_train_b, y_train_b)
print(classification_report(y_val_b, gbc_b.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))

from sklearn.svm import LinearSVC
svc_b = LinearSVC(class_weight='balanced')
svc_b.fit(x_train_b, y_train_b)
print(classification_report(y_val_b, svc_b.predict(x_val_b), target_names=['Not Fraud', 'Fraud']))

"""ok so out of all them, i got the best result for the random forest one with 0.96 everything
We can try more randomly in terms of not frauds, or try including more not frauds aand see improvements, it might help with the overfitting further
i believe some concrete math might be required to handle the trade offs

Either ways, this is a good lesson on imbalanced datasets
"""